{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from pickle import load\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model\n",
    "from nltk.translate.bleu_score import corpus_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load a clean dataset\n",
    "def load_clean_sentences(filename):\n",
    "    return load(open(filename, 'rb'))\n",
    "\n",
    "# fit a tokenizer\n",
    "def create_tokenizer(lines):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer\n",
    "\n",
    "# max sentence length\n",
    "def max_length(lines):\n",
    "    return max(len(line.split()) for line in lines)\n",
    "\n",
    "# encode and pad sequences\n",
    "def encode_sequences(tokenizer, length, lines):\n",
    "    # integer encode sequences\n",
    "    X = tokenizer.texts_to_sequences(lines)\n",
    "    # pad sequences with 0 values\n",
    "    X = pad_sequences(X, maxlen=length, padding='post')\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load datasets\n",
    "\n",
    "dataset = load_clean_sentences('english-portuguese-training-both.pkl')\n",
    "train = load_clean_sentences('english-portuguese-training.pkl')\n",
    "validation = load_clean_sentences('english-portuguese-validation.pkl')\n",
    "\n",
    "# prepare english tokenizer\n",
    "eng_tokenizer = create_tokenizer(dataset[:, 0])\n",
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "eng_length = max_length(dataset[:, 0])\n",
    "# prepare german tokenizer\n",
    "por_tokenizer = create_tokenizer(dataset[:, 1])\n",
    "por_vocab_size = len(por_tokenizer.word_index) + 1\n",
    "por_length = max_length(dataset[:, 1])\n",
    "# prepare data\n",
    "trainX = encode_sequences(por_tokenizer, por_length, train[:, 1])\n",
    "validationX = encode_sequences(por_tokenizer, por_length, validation[:, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "model = load_model('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = model.predict_classes(validationX.reshape((validationX.shape[0],validationX.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_word(n, tokenizer):\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == n:\n",
    "            return word\n",
    "    return None\n",
    "\n",
    "\n",
    "preds_text = []\n",
    "for i in preds:\n",
    "    temp = []\n",
    "    for j in range(len(i)):\n",
    "        t = get_word(i[j], eng_tokenizer)\n",
    "        if j > 0:\n",
    "            if (t == get_word(i[j-1], eng_tokenizer)) or (t == None):\n",
    "                 temp.append('')\n",
    "            else:\n",
    "                 temp.append(t)\n",
    "        else:\n",
    "            if(t == None):\n",
    "                temp.append('')\n",
    "            else:\n",
    "                temp.append(t) \n",
    "\n",
    "    preds_text.append(' '.join(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pred_df = pd.DataFrame({'actual' : validation[:,0], 'predicted' : preds_text})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3068</th>\n",
       "      <td>tom seems upset</td>\n",
       "      <td>tom seems bummed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4931</th>\n",
       "      <td>i didnt like what tom did</td>\n",
       "      <td>i didnt what tom did                          ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4685</th>\n",
       "      <td>the audience clapped when the concert was over</td>\n",
       "      <td>the united took when   was                    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5270</th>\n",
       "      <td>i let my sister use my new computer</td>\n",
       "      <td>i left my hair my    pen                      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7892</th>\n",
       "      <td>you know where it is dont you</td>\n",
       "      <td>you know  where dont  you                     ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1606</th>\n",
       "      <td>tom decided to marry mary</td>\n",
       "      <td>tom decided to  mary                          ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2059</th>\n",
       "      <td>tom didnt seem to like your cooking</td>\n",
       "      <td>tom doesnt like   his                         ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>the pond is meters deep</td>\n",
       "      <td>the basket has full different apples          ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5698</th>\n",
       "      <td>actually we dont have a choice</td>\n",
       "      <td>no didnt no  choice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>do you have any sunscreen</td>\n",
       "      <td>do you use on sunscreen                       ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1157</th>\n",
       "      <td>i was always the fastest</td>\n",
       "      <td>ive always  enough</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3696</th>\n",
       "      <td>the senator was censured by the congressional ...</td>\n",
       "      <td>the was  the of the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4274</th>\n",
       "      <td>we need tom</td>\n",
       "      <td>we need tom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250</th>\n",
       "      <td>i got mad</td>\n",
       "      <td>i got angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3220</th>\n",
       "      <td>he doesnt know anything about germany</td>\n",
       "      <td>he doesnt know anything to anymore            ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 actual  \\\n",
       "3068                                    tom seems upset   \n",
       "4931                          i didnt like what tom did   \n",
       "4685     the audience clapped when the concert was over   \n",
       "5270                i let my sister use my new computer   \n",
       "7892                      you know where it is dont you   \n",
       "1606                          tom decided to marry mary   \n",
       "2059                tom didnt seem to like your cooking   \n",
       "821                             the pond is meters deep   \n",
       "5698                     actually we dont have a choice   \n",
       "4997                          do you have any sunscreen   \n",
       "1157                           i was always the fastest   \n",
       "3696  the senator was censured by the congressional ...   \n",
       "4274                                        we need tom   \n",
       "1250                                          i got mad   \n",
       "3220              he doesnt know anything about germany   \n",
       "\n",
       "                                              predicted  \n",
       "3068   tom seems bummed                                  \n",
       "4931  i didnt what tom did                          ...  \n",
       "4685  the united took when   was                    ...  \n",
       "5270  i left my hair my    pen                      ...  \n",
       "7892  you know  where dont  you                     ...  \n",
       "1606  tom decided to  mary                          ...  \n",
       "2059  tom doesnt like   his                         ...  \n",
       "821   the basket has full different apples          ...  \n",
       "5698  no didnt no  choice                                \n",
       "4997  do you use on sunscreen                       ...  \n",
       "1157  ive always  enough                                 \n",
       "3696   the was  the of the                               \n",
       "4274        we need tom                                  \n",
       "1250        i got angry                                  \n",
       "3220  he doesnt know anything to anymore            ...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print 15 rows randomly\n",
    "pred_df.sample(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load test dataset\n",
    "\n",
    "test = load_clean_sentences('en_pt_test.pkl')\n",
    "\n",
    "testX = encode_sequences(por_tokenizer, por_length, array(test)[:, 1])\n",
    "test_preds = model.predict_classes(array(testX).reshape((array(testX).shape[0],array(testX).shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds_text = []\n",
    "for i in test_preds:\n",
    "    temp = []\n",
    "    for j in range(len(i)):\n",
    "        t = get_word(i[j], eng_tokenizer)\n",
    "        if j > 0:\n",
    "            if (t == get_word(i[j-1], eng_tokenizer)) or (t == None):\n",
    "                 temp.append('')\n",
    "            else:\n",
    "                 temp.append(t)\n",
    "        else:\n",
    "            if(t == None):\n",
    "                temp.append('')\n",
    "            else:\n",
    "                temp.append(t) \n",
    "\n",
    "    preds_text.append(' '.join(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 33)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame({'actual' : array(test)[:,0], 'predicted' : preds_text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>where can i get some ice</td>\n",
       "      <td>where can i turn ice                          ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>where is the elevator</td>\n",
       "      <td>wheres the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>do you mind</td>\n",
       "      <td>do you doubt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>whats your favorite</td>\n",
       "      <td>whats your favorite                           ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>what time is it</td>\n",
       "      <td>what time is it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>ill try my best</td>\n",
       "      <td>ill try to best</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>hello</td>\n",
       "      <td>hello</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>my mouth is watering</td>\n",
       "      <td>im getting in of   mouth                      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>let bygones be bygones</td>\n",
       "      <td>youve forget the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>here comes a bus</td>\n",
       "      <td>come it bus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>where is the cashier</td>\n",
       "      <td>wheres the box</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>i will be here for a few weeks</td>\n",
       "      <td>ill be to stay for a weeks                    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>where can i change money</td>\n",
       "      <td>where i  the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>knowledge is power</td>\n",
       "      <td>thats can</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>does the room have a bathroom</td>\n",
       "      <td>the  has have a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>i would like a drink</td>\n",
       "      <td>i want a drink</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>what time is my flight</td>\n",
       "      <td>what time is my flight                        ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>you hit one out of the park</td>\n",
       "      <td>you  nice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>i have to catch a connecting flight</td>\n",
       "      <td>i have to get a connection                    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>i am traveling for work</td>\n",
       "      <td>im out for job</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>its on the tip of my tongue</td>\n",
       "      <td>this is in of  cities                         ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>i will be here for a week</td>\n",
       "      <td>ill be stay be a week                         ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>its up to you</td>\n",
       "      <td>let you to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>that makes no difference</td>\n",
       "      <td>that makes  difference                        ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>you did great</td>\n",
       "      <td>you  nice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  actual  \\\n",
       "107             where can i get some ice   \n",
       "103                where is the elevator   \n",
       "127                          do you mind   \n",
       "159                  whats your favorite   \n",
       "48                       what time is it   \n",
       "163                      ill try my best   \n",
       "61                                 hello   \n",
       "182                 my mouth is watering   \n",
       "188               let bygones be bygones   \n",
       "171                     here comes a bus   \n",
       "115                 where is the cashier   \n",
       "44        i will be here for a few weeks   \n",
       "116             where can i change money   \n",
       "178                   knowledge is power   \n",
       "28         does the room have a bathroom   \n",
       "7                   i would like a drink   \n",
       "57                what time is my flight   \n",
       "69           you hit one out of the park   \n",
       "73   i have to catch a connecting flight   \n",
       "45               i am traveling for work   \n",
       "148          its on the tip of my tongue   \n",
       "43             i will be here for a week   \n",
       "149                        its up to you   \n",
       "196             that makes no difference   \n",
       "70                         you did great   \n",
       "\n",
       "                                             predicted  \n",
       "107  where can i turn ice                          ...  \n",
       "103        wheres the                                   \n",
       "127       do you doubt                                  \n",
       "159  whats your favorite                           ...  \n",
       "48      what time is it                                 \n",
       "163     ill try to best                                 \n",
       "61             hello                                    \n",
       "182  im getting in of   mouth                      ...  \n",
       "188   youve forget the                                  \n",
       "171        come it bus                                  \n",
       "115     wheres the box                                  \n",
       "44   ill be to stay for a weeks                    ...  \n",
       "116        where i  the                                 \n",
       "178         thats can                                   \n",
       "28       the  has have a                                \n",
       "7        i want a drink                                 \n",
       "57   what time is my flight                        ...  \n",
       "69           you  nice                                  \n",
       "73   i have to get a connection                    ...  \n",
       "45       im out for job                                 \n",
       "148  this is in of  cities                         ...  \n",
       "43   ill be stay be a week                         ...  \n",
       "149         let you to                                  \n",
       "196  that makes  difference                        ...  \n",
       "70           you  nice                                  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print 15 rows randomly\n",
    "pred_df.sample(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# map an integer to a word\n",
    "def word_for_id(integer, tokenizer):\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == integer:\n",
    "            return word\n",
    "    return None\n",
    "\n",
    "# generate target given source sequence\n",
    "def predict_sequence(model, tokenizer, source):\n",
    "    prediction = model.predict(source, verbose=0)[0]\n",
    "    integers = [argmax(vector) for vector in prediction]\n",
    "    target = list()\n",
    "    for i in integers:\n",
    "        #print(i)\n",
    "        word = word_for_id(i, tokenizer)\n",
    "        if word is None:\n",
    "            break\n",
    "        target.append(word)\n",
    "    return ' '.join(target)\n",
    "\n",
    "# evaluate the skill of the model\n",
    "def evaluate_model(model, tokenizer, sources, raw_dataset):\n",
    "    actual, predicted = list(), list()\n",
    "    for i, source in enumerate(sources):\n",
    "        # translate encoded source text\n",
    "        #print(\"Before \", source.shape)\n",
    "        source = source.reshape((1, source.shape[0]))\n",
    "        #print(\"After \", source.shape)\n",
    "        translation = predict_sequence(model, eng_tokenizer, source)\n",
    "        raw_target, raw_src = raw_dataset[i]\n",
    "        if i < 10:\n",
    "            print('src=[%s], target=[%s], predicted=[%s]' % (raw_src, raw_target, translation))\n",
    "        actual.append(raw_target.split())\n",
    "        predicted.append(translation.split())\n",
    "    # calculate BLEU score\n",
    "    print('BLEU-1: %f' % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))\n",
    "    print('BLEU-2: %f' % corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0)))\n",
    "    print('BLEU-3: %f' % corpus_bleu(actual, predicted, weights=(0.3, 0.3, 0.3, 0)))\n",
    "    print('BLEU-4: %f' % corpus_bleu(actual, predicted, weights=(0.25, 0.25, 0.25, 0.25)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "train\n",
      "src=[nao seja rude], target=[dont be rude], predicted=[dont be rude]\n",
      "src=[sou um homem ocupado], target=[im a busy man], predicted=[im a busy man]\n",
      "src=[eu nao ri], target=[i didnt laugh], predicted=[i didnt laugh]\n",
      "src=[falo rapido], target=[i talk fast], predicted=[i laughed fast]\n",
      "src=[eu o quero], target=[i want you], predicted=[i want it]\n",
      "src=[eu sou culpado], target=[im guilty], predicted=[im guilty]\n",
      "src=[volte mais tarde], target=[come back later], predicted=[come back later]\n",
      "src=[pule], target=[jump], predicted=[jump]\n",
      "src=[o que sao eles], target=[what are those], predicted=[what are those]\n",
      "src=[espere], target=[wait up], predicted=[wait]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/nltk/translate/bleu_score.py:503: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.6/site-packages/nltk/translate/bleu_score.py:503: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.6/site-packages/nltk/translate/bleu_score.py:503: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.078774\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "test\n",
      "src=[eu nao estou me sentindo bem], target=[im not well], predicted=[i not unwell]\n",
      "src=[voce me conhece], target=[you know me], predicted=[do you know me]\n",
      "src=[eu falo rapido], target=[i talk fast], predicted=[i tried fast]\n",
      "src=[tom fez arroz], target=[tom made rice], predicted=[tom got walk]\n",
      "src=[eu fiquei chateado], target=[i got upset], predicted=[i got lonely]\n",
      "src=[eu odeio perder], target=[i hate to lose], predicted=[i hate losing]\n",
      "src=[nao culpe tom], target=[dont blame tom], predicted=[dont up tom]\n",
      "src=[eles morrerao], target=[they will die], predicted=[they voted]\n",
      "src=[tom nao vai vir], target=[tom wont come], predicted=[tom will die]\n",
      "src=[leve o tom], target=[take tom], predicted=[take that tom]\n",
      "BLEU-1: 0.070933\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# test on some training sequences\n",
    "print('train')\n",
    "evaluate_model(model, eng_tokenizer, trainX, train)\n",
    "# test on some test sequences\n",
    "print('test')\n",
    "evaluate_model(model, eng_tokenizer, validationX, validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final test\n",
      "src=[eu perdi meu passaporte], target=[i have lost my passport], predicted=[i felt hungry]\n",
      "src=[alguem roubou meu dinheiro], target=[someone stole my money], predicted=[how is money]\n",
      "src=[socorro], target=[help], predicted=[help]\n",
      "src=[pode trazer a conta], target=[may i have the bill], predicted=[do it show me]\n",
      "src=[eu gostaria de sobremesa], target=[i would like dessert], predicted=[i like driving]\n",
      "src=[eu gostaria de pedir], target=[i would like to order], predicted=[i was fun]\n",
      "src=[posso ver um menu], target=[may i see a menu], predicted=[can i see]\n",
      "src=[quero uma bebida], target=[i would like a drink], predicted=[i want a knife]\n",
      "src=[eu gostaria de um pouco de agua], target=[i would like some water], predicted=[i need both bed]\n",
      "src=[uma mesa para dois], target=[a table for two], predicted=[take a minute]\n",
      "BLEU-1: 0.100276\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/nltk/translate/bleu_score.py:503: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.6/site-packages/nltk/translate/bleu_score.py:503: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.6/site-packages/nltk/translate/bleu_score.py:503: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# load model\n",
    "#model = load_model('model.h5')\n",
    "\n",
    "print('final test')\n",
    "evaluate_model(model, eng_tokenizer, array(testX), array(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
